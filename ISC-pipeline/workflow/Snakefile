# ---- begin snakebids boilerplate ----------------------------------------------

import snakebids
from snakebids import bids, generate_inputs
from os.path import join
import pandas as pd

configfile: "config/snakebids.yml"

H_to_hemi = dict({'L': 'lh', 'R': 'rh'})

# writes inputs_config.yml and updates config dict
inputs = snakebids.generate_inputs(
    bids_dir=config["fMRIprep_dir"],
    pybids_inputs=config["pybids_inputs"],
    pybids_config=["bids", "derivatives"],
    # derivatives=config["derivatives"],
    #participant_label=config["participant_label"],
    #exclude_participant_label=config["exclude_participant_label"],
    use_bids_inputs=True,
)


# this adds constraints to the bids naming
wildcard_constraints:
    **snakebids.get_wildcard_constraints(config["pybids_inputs"]),


# ---- end snakebids boilerplate ------------------------------------------------


# additional constraints for wildcards not defined from inputs
wildcard_constraints:
    desc="[a-zA-Z0-9]+",
    fwhm="[0-9]+",
    confounds="[0-9]+",
    surfname='white|pial|sphere.reg',
    volname='T1'

#include: 'rules/common.smk'

# rule all:
#     input:
#         # using the zip lists to expand over all scans, note use of the zip option in expand:
#         denoised = expand(
#                     expand(
#                 bids(root="results/denoised", datatype="func",
#                     desc="{{desc}}",
#                     fwhm="{{fwhm}}",
#                     confounds="{{confounds_idx}}",
#                     suffix="bold.nii.gz",
#                     **inputs["preproc_bold"].wildcards
#                 ),
#                 zip,
#                 **inputs["preproc_bold"].zip_lists
#             ),
#             fwhm=config["fwhm"],
#             confounds_idx=range(1, len(config["confounds"]) + 1),
#             desc=["denoised", "AROMAdenoised"],
#         ),
#     default_target: True


## Smoothing and denoising rules
rule smooth:
    input:
        nii  = inputs["preproc_bold"].path,
        json = re.sub(".nii.gz", ".json", inputs["preproc_bold"].path),
    params:
        fwhm = lambda wildcards: float(wildcards.fwhm),
    output:
        nii  = bids(root="results/denoised", datatype="func", desc="smoothed", fwhm="{fwhm}",
                    suffix="bold.nii.gz", **inputs["preproc_bold"].wildcards),    
        json = bids(root="results/denoised", datatype="func", desc="smoothed", fwhm="{fwhm}",
                    suffix="bold.json", **inputs["preproc_bold"].wildcards),
    group:
        "subj"
    script:
        "scripts/smooth.py"


rule denoise:
    input:
        nii  = bids(root="results/denoised", datatype="func", desc="smoothed", fwhm="{fwhm}",
                    suffix="bold.nii.gz", **inputs["preproc_bold"].wildcards),
        json = bids(root="results/denoised", datatype="func", desc="smoothed", fwhm="{fwhm}",
                    suffix="bold.json", **inputs["preproc_bold"].wildcards),
        confounds_tsv = inputs["confounds"].path,
        mask_nii = inputs["preproc_mask"].path,
    params:
        confounds_to_use = lambda wildcards: config["confounds"][
            int(wildcards.confounds_idx) - 1
        ]["regressors"],
        confounds_name = lambda wildcards: config["confounds"][
            int(wildcards.confounds_idx) - 1
        ]["name"],
        standardize = True,
        detrend     = True,
        low_pass    = False,
        high_pass   = False,
    output:
        nii  = bids(root="results/denoised", datatype="func", desc="denoised", fwhm="{fwhm}", confounds="{confounds_idx}",
                    suffix="bold.nii.gz", **inputs["preproc_bold"].wildcards),
        json = bids(root="results/denoised", datatype="func", desc="denoised", fwhm="{fwhm}", confounds="{confounds_idx}",
                    suffix="bold.json", **inputs["preproc_bold"].wildcards),
    group:
        "subj"
    script:
        "scripts/denoise.py"


# Dummy rules
rule just_denoise:
    input:
        denoised=expand(
            expand(
                rules.denoise.output.nii,
                zip,
                **inputs["preproc_bold"].zip_lists,
                allow_missing=True
            ),
            fwhm=config["fwhm"],
            confounds_idx=range(1, len(config["confounds"]) + 1)
        )


rule smooth_denoise:
    input:
        # using the zip lists to expand over all scans, note use of the zip option in expand:
        denoised = expand(
                    expand(
                        bids(root="results/denoised",
                            datatype="func",
                            desc="{{desc}}",
                            fwhm="{{fwhm}}",
                            confounds="{{confounds_idx}}",
                            suffix="bold.nii.gz",
                            **inputs["preproc_bold"].wildcards
                        ),
                        zip,
                        **inputs["preproc_bold"].zip_lists
                    ),
                fwhm=config["fwhm"],
                confounds_idx=range(1, len(config["confounds"]) + 1),
                desc="denoised",
            ),

## Generate midthickness rules
rule extract_from_tar:
    input: 
        tar = config['freesurfer_tar']
    params:
        out_folder = config['freesurfer_root'],
        file_in_tar = 'sub-{subject}/{modality}/{filename}'
    output: 
        filename = join(config['freesurfer'],'{modality,surf|mri}','{filename}')
    group: 'participant1'
    shell: 'mkdir -p {params.out_folder} && tar -C {params.out_folder} --extract --file={input.tar} {params.file_in_tar}'

def get_gifti_input (wildcards):
    if wildcards.surfname == 'pial': #add .T1 to the name (since pial is a symlink to pial.T1) so can use if extracting from tar
        return join(config['freesurfer'],'surf','{hemi}.{surfname}.T1'.format(hemi=H_to_hemi[wildcards.hemi],surfname=wildcards.surfname))
    else:
        return join(config['freesurfer'],'surf','{hemi}.{surfname}'.format(hemi=H_to_hemi[wildcards.hemi],surfname=wildcards.surfname))
        
rule convert_to_gifti:
    input: get_gifti_input
    output: bids(root='results/midthickness', subject='{subject}', hemi='{hemi}', suffix='{surfname}.surf.gii', space='fsaverage')
    params: 
        license = config['fs_license']
    container: config['singularity_freesurfer']
    log: 'logs/convert_to_gifti/sub-{subject}_{hemi}_{surfname}.log'
    group: 'participant1'
    shell: 'FS_LICENSE={params.license} mris_convert {input} {output} &> {log}'


rule convert_to_nifti:
    input: join(config['freesurfer'],'mri','{volname}.mgz')
    output: bids(root='results/midthickness',subject='{subject}',suffix='{volname}.nii.gz')
    params: 
        license = config['fs_license']
    container: config['singularity_freesurfer']
    log: 'logs/convert_to_nifti/sub-{subject}_{volname}.log'
    group: 'participant1'
    shell: 'FS_LICENSE={params.license} mri_convert {input} {output} &> {log}'


rule get_tkr2scanner:
    input: 
        t1 = bids(root='results/midthickness',subject='{subject}',suffix='T1.nii.gz')
    output:
        tkr2scanner = bids(root='results/midthickness',subject='{subject}',suffix='tkr2scanner.xfm')
    params: 
        license = config['fs_license']
    container: config['singularity_freesurfer']
    log: 'logs/get_tkr2scanner/sub-{subject}.log'
    group: 'participant1'
    shell: 'FS_LICENSE={params.license} mri_info {input.t1} --tkr2scanner > {output.tkr2scanner} 2> {log}'


rule apply_surf_tkr2scanner:
    input: 
        surf = bids(root='results/midthickness',subject='{subject}',hemi='{hemi}',suffix='{surfname}.surf.gii',space='fsaverage'),
        tkr2scanner = bids(root='results/midthickness',subject='{subject}',suffix='tkr2scanner.xfm')
    output: 
        surf = bids(root='results/midthickness',subject='{subject}',hemi='{hemi}',space='native',suffix='{surfname}.surf.gii')
    threads: 8
    container: config['singularity_connectome_workbench']
    log: 'logs/apply_surf_tkr2scanner/sub-{subject}_{hemi}_{surfname}.log'
    group: 'participant1'
    shell: 'wb_command -surface-apply-affine {input.surf} {input.tkr2scanner} {output.surf} &> {log}'


rule gen_midthickness:
    input:
        white = bids(root='results/midthickness',subject='{subject}',hemi='{hemi}',suffix='white.surf.gii',space='{space}'),
        pial  = bids(root='results/midthickness',subject='{subject}',hemi='{hemi}',suffix='pial.surf.gii',space='{space}')
    output: 
        midthickness = bids(root='results/midthickness',subject='{subject}',hemi='{hemi}',suffix='midthickness.surf.gii',space='{space}')
    container: config['singularity_connectome_workbench']
    threads: 8
    log: 'logs/gen_midthickness/sub-{subject}_{hemi}_{space}.log'
    group: 'participant1'
    shell: 'wb_command -surface-average {output.midthickness} -surf {input.white} -surf {input.pial} &> {log}'


# Dummy rule
rule generate_midthickness:
    input:
        midthickness = expand(
                        bids(root='results/midthickness',subject='{subject}',hemi='{hemi}',space='native',suffix='midthickness.surf.gii'),
                        subject=inputs.subjects,
                        hemi=config['hemi'])


## Resample to surface rules
rule vol2surf:
    input:
        bold = bids(root="results/denoised",
                    datatype="func",
                    desc="denoised",
                    fwhm="{fwhm}",
                    confounds="{confounds_idx}",
                    space="T1w",
                    subject="{subject}",
                    task="{task}",
                    run="{run}",
                    suffix="bold.nii.gz",
                ),
        #config['bold_dir']+"/sub-{subject}/func/sub-{subject}_task-{task}_run-{run}_space-T1w_desc-denoised_fwhm-{fwhm}_confounds-{conf}_bold.nii.gz",
        midthickness = bids(root="results/midthickness",subject="{subject}",hemi="{hemi}",space="native",suffix="midthickness.surf.gii"),
        white        = bids(root="results/midthickness",subject="{subject}",hemi="{hemi}",space="native",suffix="white.surf.gii"),
        pial         = bids(root="results/midthickness",subject="{subject}",hemi="{hemi}",space="native",suffix="pial.surf.gii")
    output:
        bids(root="results/resampled2fsLR",
            datatype="func",
            fwhm="{fwhm}",
            confounds="{confounds_idx}",
            desc="denoised",
            hemi="{hemi}",
            space="native",
            suffix="bold.func.gii",
            subject="{subject}",
            task="{task}",
            run="{run}"
        )
        #bids(root='resampled2fsLR',subject='{subject}',hemi='{hemi}',space='native',suffix='pial.surf.gii')
        #config['output_dir']+"/sub-{subject}/sub-{subject}_hemi-{hemi}_task-{task}_run-{run}_space-native_desc-denoised_fwhm-{fwhm}_confounds-{conf}_bold.func.gii"
    shell:
        "wb_command -volume-to-surface-mapping {input.bold} {input.midthickness} {output} -ribbon-constrained {input.white} {input.pial}"


rule metric_resample:
    input:
        vol2surf_out  = rules.vol2surf.output,
        curr_sphere   = bids(root='results/midthickness',subject='{subject}',hemi='{hemi}',space='fsaverage',suffix='sphere.reg.surf.gii'),
        #config['surf_dir']+"/sub-{subject}/sub-{subject}_hemi-{hemi}_space-fsaverage_sphere.reg.surf.gii",
        target_sphere = "resources/standard_mesh_atlases/resample_fsaverage/fs_LR-deformed_to-fsaverage.{hemi}.sphere.32k_fs_LR.surf.gii"
    output:
        bids(root="results/resampled2fsLR/32k_space_surfaces",
            datatype="func",
            fwhm="{fwhm}",
            confounds="{confounds_idx}",
            desc="denoised",
            hemi="{hemi}",
            space="fsLR_den-32k",
            suffix="bold.func.gii",
            subject="{subject}",
            task="{task}",
            run="{run}"
        )
        #config['output_dir']+"/32k_space_surfaces/sub-{subject}/sub-{subject}_hemi-{hemi}_task-{task}_run-{run}_space-fsLR_den-32k_desc-denoised_fwhm-{fwhm}_confounds-{conf}_bold.func.gii"
    shell:
        "wb_command -metric-resample {input.vol2surf_out} {input.curr_sphere} {input.target_sphere} BARYCENTRIC {output}"


# Dummy rule
rule resample2fsLR:
    input:
        fsLR = expand(
                expand(rules.metric_resample.output,
                    zip,
                    **inputs["preproc_bold"].zip_lists,
                    allow_missing=True
                ),
                fwhm=config["fwhm"],
                confounds_idx=range(1, len(config["confounds"]) + 1),
                hemi=config['hemi']
            ),
    #default_target: True


## Temporal resampling
rule temp_resample:
    input:
        func = rules.metric_resample.output
    params:
        original_TR = config['original_TR'],
        target_TR = config['target_TR']
    output:
        bids(root="results/temporalResampled",
            datatype="func",
            fwhm="{fwhm}",
            confounds="{confounds_idx}",
            desc="denoised",
            hemi="{hemi}",
            space="fsLR_den-32k",
            suffix="bold.func.gii",
            subject="{subject}",
            task="{task}",
            run="{run}"
        )
    script:
        "scripts/tempResample.py"

# Dummy rule
rule temporal_resample:
    input:
        fsLR = expand(
                expand(rules.temp_resample.output,
                    zip,
                    **inputs["preproc_bold"].zip_lists,
                    allow_missing=True
                ),
                fwhm=config["fwhm"],
                confounds_idx=range(1, len(config["confounds"]) + 1),
                hemi=config['hemi']
            ),
    default_target: True

# ## Parcellate
# rule parcellate:
#     input:
#         func = rules.temporal_resample.output
#         atlas = ''
#     output:

#     script:
